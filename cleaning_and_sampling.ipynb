{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSA4264 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data (STORE FILES IN SUBFOLDER CALLED DATA)\n",
    "data2020_df = pd.read_csv('./data/Reddit-Threads_2020-2021.csv',  lineterminator='\\n', encoding='utf8')\n",
    "data2022_df = pd.read_csv('./data/Reddit-Threads_2022-2023.csv', lineterminator='\\n', encoding='utf8')\n",
    "\n",
    "#Remove comments which are [Removed] or [Deleted]\n",
    "data2020_df = data2020_df[~data2020_df['text'].str.contains(r'\\[removed\\]', na=False)]\n",
    "data2020_df = data2020_df[~data2020_df['text'].str.contains(r'\\[deleted\\]', na=False)]\n",
    "data2022_df = data2022_df[~data2022_df['text'].str.contains(r'\\[removed\\]', na=False)]\n",
    "data2022_df = data2022_df[~data2022_df['text'].str.contains(r'\\[deleted\\]', na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2663782\n",
      "1840541\n"
     ]
    }
   ],
   "source": [
    "#print(len(data2020_df))\n",
    "#print(len(data2022_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "\n",
    "def clean_data(df):\n",
    "  pd.options.mode.copy_on_write = True\n",
    "\n",
    "  #Remove rows with empty review_text\n",
    "  df = df[df['text'].notnull()]\n",
    "\n",
    "  #Remove emoji rows\n",
    "  df['text'] = df['text'].apply(lambda x: emoji.replace_emoji(x,''))\n",
    "\n",
    "  #Remove punctuation\n",
    "  df['text'] = df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "  #Remove all rows that has non ASCII characters\n",
    "  df = df[df['text'].apply(lambda x: all(ord(c) < 128 for c in x))]\n",
    "\n",
    "  #Set all to lower case\n",
    "  df['text'] = df['text'].str.lower()\n",
    "\n",
    "  '''\n",
    "  #Remove rows that are not in English\n",
    "  count = 1\n",
    "  for index, row in df.iterrows():\n",
    "      try:\n",
    "        if detect(row['text']) != 'en':\n",
    "          df.drop(index, inplace=True)\n",
    "          print(row['text'])\n",
    "          print(count)\n",
    "          count += 1\n",
    "      except:\n",
    "        df.drop(index, inplace=True)\n",
    "        print(\"error for\", row['text'])\n",
    "  '''\n",
    "\n",
    "  df = df.reset_index(drop=True)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_2020 = clean_data(data2020_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_2022 = clean_data(data2022_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    }
   ],
   "source": [
    "#Get random sample of 500000\n",
    "length_2020 = len(cleaned_2020)\n",
    "length_2022 = len(cleaned_2022)\n",
    "size2020 = int(500000 * (length_2020/(length_2020 + length_2022)))\n",
    "size2022 = 500000 - size2020\n",
    "\n",
    "sample_2020 = cleaned_2020.sample(n=size2020, random_state=42)\n",
    "sample_2022 = cleaned_2022.sample(n=size2022, random_state=42)\n",
    "\n",
    "combined_df = pd.concat([sample_2020, sample_2022], axis=0)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(len(combined_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298642\n",
      "201358\n"
     ]
    }
   ],
   "source": [
    "#print(size2020)\n",
    "#print(size2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n",
      "          text            timestamp   username  \\\n",
      "count   500000               500000     500000   \n",
      "unique  480871               498422      42403   \n",
      "top             2021-07-21 02:10:03  [deleted]   \n",
      "freq      1423                    3      12521   \n",
      "\n",
      "                                                     link    link_id  \\\n",
      "count                                              500000     500000   \n",
      "unique                                             500000      70648   \n",
      "top     /r/singapore/comments/11do8on/rsingapore_rando...  t3_homxdq   \n",
      "freq                                                    1       1188   \n",
      "\n",
      "        parent_id       id subreddit_id  \\\n",
      "count      500000   500000       500000   \n",
      "unique     374430   500000            3   \n",
      "top     t3_homxdq  jaayf9p     t5_2qh8c   \n",
      "freq          559        1       450203   \n",
      "\n",
      "                                               moderation  \n",
      "count                                              500000  \n",
      "unique                                                 37  \n",
      "top     {'removal_reason': None, 'collapsed': False, '...  \n",
      "freq                                               151587  \n"
     ]
    }
   ],
   "source": [
    "print(len(combined_df))\n",
    "print(combined_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data to csv (Only need to run once)\n",
    "#combined_df.to_csv('Reddit_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
